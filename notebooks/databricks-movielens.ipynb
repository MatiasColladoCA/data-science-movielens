{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc0a9c4-f6b6-4306-8a7b-f873d940c017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Vista rapida de datasets con Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b06d20b-58cb-44b9-9526-2e9142f11a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# El SparkSession ya existe en el notebook de Databricks por defecto\n",
    "csv_files = [\n",
    "    \"genome-scores.csv\",\n",
    "    \"genome-tags.csv\",\n",
    "    \"links.csv\",\n",
    "    \"movies.csv\",\n",
    "    \"ratings.csv\",\n",
    "    \"tags.csv\"\n",
    "]\n",
    "\n",
    "base_path = \"/Volumes/workspace/movie/movielens/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b25dba-73ec-44bc-ac68-0a9c9257785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Carga Optimizada y Definici√≥n de Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4cb8eb-4e47-4487-9174-004d0b714255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Definici√≥n de Schemas ---\n",
    "# Evita errores como por ejemplo suma de strings y agiliza la lectura\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, TimestampType\n",
    "\n",
    "# Schema para movies.csv\n",
    "movies_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Schema para ratings.csv\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True) # Lo leeremos como int y luego transformaremos\n",
    "])\n",
    "\n",
    "# --- Carga de Datos con Schemas ---\n",
    "base_path = \"/Volumes/workspace/movie/movielens/\"\n",
    "\n",
    "# Cargar los datos principales usando los schemas definidos\n",
    "movies_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(movies_schema).load(base_path + \"movies.csv\")\n",
    "ratings_df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(ratings_schema).load(base_path + \"ratings.csv\")\n",
    "\n",
    "print(\"Datos de pel√≠culas cargados con schema:\")\n",
    "movies_df.printSchema()\n",
    "movies_df.show(5, truncate=False)\n",
    "\n",
    "print(\"\\nDatos de ratings cargados con schema:\")\n",
    "ratings_df.printSchema()\n",
    "ratings_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89e698f-9c06-4ff8-9d24-32e68127803e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crear vistas temporales para poder consultarlas con SQL\n",
    "movies_df.createOrReplaceTempView(\"movies_view\")\n",
    "ratings_df.createOrReplaceTempView(\"ratings_view\")\n",
    "\n",
    "# --- Consultas B√°sicas con Spark SQL ---\n",
    "\n",
    "# 1. Ver las primeras 10 pel√≠culas\n",
    "print(\"Primeras 10 pel√≠culas:\")\n",
    "spark.sql(\"SELECT title, genres FROM movies_view LIMIT 10\").show(truncate=False)\n",
    "\n",
    "# 2. Encontrar todas las pel√≠culas de 'Toy Story'\n",
    "print(\"\\nPel√≠culas de 'Toy Story':\")\n",
    "spark.sql(\"SELECT * FROM movies_view WHERE title LIKE 'Toy Story%'\").show(truncate=False)\n",
    "\n",
    "# 3. Ver los ratings m√°s altos (por encima de 4.5)\n",
    "print(\"\\nRatings m√°s altos:\")\n",
    "spark.sql(\"SELECT userId, movieId, rating FROM ratings_view WHERE rating > 4.5 ORDER BY rating DESC\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad89c93-577c-4a49-8e61-f87b8908ce2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(movies_df.select(\"genres\").distinct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cc16788-cc5d-4077-bb43-bd3433412dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformaci√≥n y Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8444eaa-5105-4245-98e1-a7a1128c4183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71317b8-d42e-49b7-9bf1-2b8f56c1bf7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def remove_duplicates(df: DataFrame, subset_cols: list, df_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Identifica y elimina filas duplicadas de un DataFrame bas√°ndose en un subconjunto de columnas. La funci√≥n agrega una capa de auditaci√≥n y reporte que dropDuplicates no logra.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): El DataFrame de Spark a limpiar.\n",
    "        subset_cols (list): Lista de nombres de columna para considerar la unicidad.\n",
    "        df_name (str): Nombre descriptivo del DataFrame, usado para el logging.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Un nuevo DataFrame con los duplicados eliminados.\n",
    "    \"\"\"\n",
    "    initial_count = df.count()\n",
    "    unique_count = df.select(subset_cols).distinct().count()\n",
    "    \n",
    "    duplicates_found = initial_count - unique_count\n",
    "    \n",
    "    print(f\"--- Limpieza de Duplicados para: {df_name} ---\")\n",
    "    print(f\"Filas iniciales: {initial_count}\")\n",
    "    print(f\"Filas √∫nicas basadas en {subset_cols}: {unique_count}\")\n",
    "    print(f\"Duplicados a eliminar: {duplicates_found}\\n\")\n",
    "    \n",
    "    if duplicates_found > 0:\n",
    "        df_cleaned = df.dropDuplicates(subset_cols)\n",
    "        print(f\"Duplicados eliminados. Nuevo total de filas: {df_cleaned.count()}\\n\")\n",
    "        return df_cleaned\n",
    "    else:\n",
    "        print(\"No se encontraron duplicados. El DataFrame no fue modificado.\\n\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b47d963e-03ab-4d97-bcdb-09e9114df2c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Limpieza de Duplicados ---\n",
    "# Eliminamos posibles pel√≠culas duplicadas antes de cualquier transformaci√≥n.\n",
    "movies_df_clean = remove_duplicates(df=movies_df, subset_cols=['movieId'], df_name='Movies DataFrame Original')\n",
    "\n",
    "# # Eliminamos posibles pel√≠culas duplicadas antes de cualquier transformaci√≥n.\n",
    "# movies_df_clean = remove_duplicates(df=movies_df, subset_cols=['movieId'], df_name='Movies DataFrame Original')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79507ddb-6c78-410b-95a3-d399c47a5d10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Separaci√≥n de a√±o y generos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74b624d-47bb-4d61-bfd4-c8ce51cd82ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3368a7b8-66ed-4424-95a7-8725cfbc1451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split, explode, regexp_extract, from_unixtime, to_timestamp, lit, when\n",
    "\n",
    "# --- Transformaci√≥n del DataFrame de Pel√≠culas (Versi√≥n Profundamente Limpia) ---\n",
    "# 1. Extraer el a√±o de forma segura (usando try_cast).\n",
    "# 2. Separar los g√©neros.\n",
    "# 3. Convertir el marcador \"(no genres listed)\" a NULL para consistencia.\n",
    "\n",
    "movies_transformed_df = movies_df_clean.withColumn(\n",
    "    \"year\",\n",
    "    regexp_extract(col(\"title\"), r\"\\((\\d{4})\\)\", 1).try_cast(\"int\")\n",
    ").withColumn(\n",
    "    \"genre\",\n",
    "    explode(split(col(\"genres\"), \"\\\\|\"))\n",
    ").withColumn(\n",
    "    # Reemplazamos el texto de marcador por un verdadero NULL\n",
    "    \"genre\",\n",
    "    when(col(\"genre\") == \"(no genres listed)\", lit(None)).otherwise(col(\"genre\"))\n",
    ").select(\n",
    "    \"movieId\",\n",
    "    \"title\",\n",
    "    \"year\",\n",
    "    \"genre\"\n",
    ")\n",
    "\n",
    "print(\"Pel√≠culas transformadas (g√©neros explotados y valores nulos estandarizados):\")\n",
    "movies_transformed_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df460c8-b243-4bf7-89c5-951c9b211625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def show_unique_values(df: DataFrame, df_name: str, limit: int = 20, ignore_cols: list = []):\n",
    "    \"\"\"\n",
    "    Muestra los valores √∫nicos de cada columna de un DataFrame para su validaci√≥n.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): El DataFrame de Spark a analizar.\n",
    "        df_name (str): El nombre del DataFrame para imprimir en el encabezado.\n",
    "        limit (int, optional): N√∫mero m√°ximo de valores √∫nicos a mostrar por columna.\n",
    "                               Si es None, muestra todos. Por defecto es None.\n",
    "        ignore_cols (list): Lista de nombres de columna que se omitir√°n en el an√°lisis.\n",
    "    \n",
    "    Evitar:\n",
    "    distinct().collect()\n",
    "\n",
    "        ‚û° intenta traer todo al driver\n",
    "        ‚û° provoca un shuffle enorme\n",
    "        ‚û° se queda ejecutando por mucho tiempo o hasta agotar memoria\n",
    "    \"\"\"\n",
    "    print(f\"--- Validaci√≥n de Valores √önicos para: {df_name} ---\\n\")\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if column_name in ignore_cols:\n",
    "            continue\n",
    "\n",
    "        print(f\"Columna: '{column_name}'\")\n",
    "\n",
    "        distinct_df = df.select(column_name).distinct()\n",
    "\n",
    "        # Mostrar n valores\n",
    "        distinct_df.show(limit, truncate=False)\n",
    "\n",
    "        n = limit if limit is not None else 20\n",
    "\n",
    "        # Contar total\n",
    "        total = distinct_df.count()\n",
    "        print(f\"Total valores √∫nicos: {total}\")\n",
    "\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9cd2e8-1c2e-4f33-9a9f-84076e1445c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar valores √∫nicos para el DataFrame de ratings\n",
    "ignore = [\"timestamp\", \"movieId\", \"userId\"]\n",
    "show_unique_values(ratings_df, \"Ratings Transformado\", ignore_cols=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03918a63-49dd-4fb8-97b2-e392904fd9a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Transformaci√≥n del DataFrame de Ratings (Versi√≥n Limpia) ---\n",
    "# 1. Convertir el timestamp de Unix Epoch a un formato de fecha legible.\n",
    "# 2. Convertir ratings inv√°lidos (nulos o 0.0) a NULL.\n",
    "\n",
    "ratings_transformed_df = ratings_df.withColumn(\n",
    "    \"rating_timestamp\",\n",
    "    to_timestamp(from_unixtime(col(\"timestamp\")))\n",
    ").withColumn(\n",
    "    # Si el rating es nulo o 0.0, se convierte a NULL. De lo contrario, se mantiene el valor.\n",
    "    \"rating\",\n",
    "    when((col(\"rating\").isNull()) | (col(\"rating\") <= 0.0), lit(None)).otherwise(col(\"rating\"))\n",
    ").select(\n",
    "    \"userId\",\n",
    "    \"movieId\",\n",
    "    \"rating\",\n",
    "    \"timestamp\"\n",
    ")\n",
    "\n",
    "print(\"\\nRatings transformados y limpios:\")\n",
    "ratings_transformed_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5e7ae17-56fa-4a67-a288-c8cb16890bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Buscar valores √∫nicos para entender y limpiar mejor las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "502d0536-c0a5-49e4-9b52-43c80cb87766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar valores √∫nicos para el DataFrame de pel√≠culas\n",
    "ignore = [\"movieId\", \"title\"]\n",
    "show_unique_values(movies_transformed_df, \"Movies Transformado\", limit=100, ignore_cols=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daf7c01d-4087-4b3b-a0c3-01a050bea139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtrar filas donde 'genre' es exactamente \"We're Comin' To Get Ya!\\\" (2014)\"\n",
    "target_genre = \" We're Comin' To Get Ya!\\\"\\\" (2014)\\\"\"\n",
    "rows_to_remove_df = movies_transformed_df.filter(col(\"genre\") == target_genre)\n",
    "num_rows_removed = rows_to_remove_df.count()\n",
    "\n",
    "# Eliminar esas filas del DataFrame\n",
    "movies_filtered_df = movies_transformed_df.filter(col(\"genre\") != target_genre)\n",
    "\n",
    "print(f\"Filas eliminadas con g√©nero '{target_genre}': {num_rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f330c096-8919-468c-b30e-9589a455a0a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar valores √∫nicos para el DataFrame de pel√≠culas\n",
    "ignore = [\"movieId\", \"title\"]\n",
    "show_unique_values(movies_filtered_df, \"Movies Transformado\", limit=100, ignore_cols=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d95bb95-7ea3-4171-b01f-30b01e733056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar valores √∫nicos para el DataFrame de ratings\n",
    "ignore = [\"timestamp\", \"movieId\", \"userId\"]\n",
    "show_unique_values(ratings_transformed_df, \"Ratings Transformado\", ignore_cols=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef75b90-414e-435a-b6fa-c870a806e77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# --- Paso de Limpieza Avanzada: Eliminar T√≠tulos Colados en G√©neros ---\n",
    "\n",
    "# 1. Primero, inspeccionemos qu√© filas coinciden con nuestro patr√≥n sospechoso.\n",
    "#    Usamos .rlike() para aplicar la expresi√≥n regular.\n",
    "#    La regex busca cualquier string que contenga \"(4 d√≠gitos)\" y luego una comilla doble.\n",
    "print(\"üîç Filas identificadas con un posible t√≠tulo en la columna 'genre':\")\n",
    "suspicious_rows_df = movies_transformed_df.filter(col(\"genre\").rlike('.*\\(\\d{4}\\).*\"'))\n",
    "suspicious_rows_df.show(truncate=False)\n",
    "\n",
    "# 2. Ahora, eliminamos estas filas del DataFrame.\n",
    "#    El s√≠mbolo '~' es el operador \"NOT\", por lo que filtramos para mantener todo lo que NO coincide con el patr√≥n.\n",
    "movies_cleaned_df = movies_transformed_df.filter(~col(\"genre\").rlike('.*\\(\\d{4}\\).*\"'))\n",
    "\n",
    "print(f\"\\n‚úÖ Se han eliminado {suspicious_rows_df.count()} filas incorrectas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ec306a8-802d-4282-b50b-9ffbdc17edaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Buscar valores nulos y borrarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab10b5c-e7c8-4308-ad79-aa35fe1ea5b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "from pyspark.sql.functions import count, col, sum as spark_sum\n",
    "\n",
    "total_count_movies = movies_transformed_df.count()\n",
    "\n",
    "null_props_movies = movies_transformed_df.agg(\n",
    "    *[(spark_sum(col(c).isNull().cast(\"int\")) / total_count_movies).alias(c)\n",
    "      for c in movies_transformed_df.columns]\n",
    ")\n",
    "\n",
    "null_props_movies.show()\n",
    "\n",
    "\n",
    "total_count_ratings = ratings_transformed_df.count()\n",
    "\n",
    "null_props_ratings = ratings_transformed_df.agg(\n",
    "    *[(spark_sum(col(c).isNull().cast(\"int\")) / total_count_ratings).alias(c)\n",
    "      for c in ratings_transformed_df.columns]\n",
    ")\n",
    "\n",
    "null_props_ratings.show()\n",
    "\n",
    "\n",
    "# Antes\n",
    "# df.count() ya hace un full scan del DataFrame.\n",
    "# .select([...]).show(), que vuelve a disparar otro full scan + agregaciones sobre todas las columnas.\n",
    "# genera un plano l√≥gico con miles de operaciones separadas,\n",
    "# usa count(when()), que es m√°s lento,\n",
    "# divide por un count de otro DataFrame,\n",
    "# y Spark debe recalcular muchas cosas.\n",
    "\n",
    "# La versi√≥n optimizada:\n",
    "# usa agg() ‚Üí Spark lo optimiza como un single pass aggregation,\n",
    "# isNull().cast(\"int\") es vectorizado,\n",
    "# evita m√∫ltiples scans y shuffles,\n",
    "# usa el total correcto por DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18a6765-a617-4a25-b963-bd6f82f431c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def drop_nulls_and_report(df: DataFrame, df_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina todas las filas que contienen al menos un valor nulo y reporta\n",
    "    la cantidad de filas eliminadas.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): El DataFrame de Spark a limpiar.\n",
    "        df_name (str): Nombre descriptivo del DataFrame para el logging.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Un nuevo DataFrame sin filas nulas.\n",
    "    \"\"\"\n",
    "    initial_count = df.count()\n",
    "    \n",
    "    print(f\"--- Eliminaci√≥n de Nulos para: {df_name} ---\")\n",
    "    print(f\"Filas iniciales: {initial_count}\")\n",
    "    \n",
    "    # na.drop() elimina cualquier fila que contenga un valor nulo en CUALQUIER columna\n",
    "    df_cleaned = df.na.drop()\n",
    "    \n",
    "    final_count = df_cleaned.count()\n",
    "    rows_dropped = initial_count - final_count\n",
    "    \n",
    "    print(f\"Filas eliminadas con nulos: {rows_dropped}\")\n",
    "    print(f\"Filas finales: {final_count}\\n\")\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a829c2-ae70-427b-a50f-caa0cc71cb62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpiar el DataFrame de pel√≠culas\n",
    "movies_clean_df = drop_nulls_and_report(movies_transformed_df, \"Movies Transformado\")\n",
    "\n",
    "# Limpiar el DataFrame de ratings\n",
    "ratings_clean_df = drop_nulls_and_report(ratings_transformed_df, \"Ratings Transformado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef6f559-d6cb-4b9c-9050-ad8331d31797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agregaci√≥n y Joins simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "706eba9c-9742-45cf-9147-57d925790828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Agregaciones y Joins Simples ---\n",
    "\n",
    "# Spark SQL: Contar el n√∫mero total de ratings\n",
    "total_ratings_sql = spark.sql(\"SELECT COUNT(*) as total_ratings FROM ratings_view\").collect()[0][0]\n",
    "print(f\"Total de ratings en la tabla (SQL): {total_ratings_sql}\")\n",
    "\n",
    "# DataFrame API: Hacer lo mismo\n",
    "total_ratings_df = ratings_df.count()\n",
    "print(f\"Total de ratings en la tabla (DataFrame API): {total_ratings_df}\")\n",
    "\n",
    "# Spark SQL: Encontrar las 5 pel√≠culas con m√°s ratings\n",
    "print(\"\\nTop 5 pel√≠culas con m√°s ratings (SQL):\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        movieId,\n",
    "        COUNT(*) as num_ratings\n",
    "    FROM ratings_view\n",
    "    GROUP BY movieId\n",
    "    ORDER BY num_ratings DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "# Join simple con Spark SQL: Unir una pel√≠cula con sus ratings\n",
    "print(\"\\nJoin simple: Ver los ratings para la pel√≠cula 'Jumanji':\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        m.title,\n",
    "        r.userId,\n",
    "        r.rating\n",
    "    FROM movies_view m\n",
    "    JOIN ratings_view r ON m.movieId = r.movieId\n",
    "    WHERE m.title = 'Jumanji (1995)'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a4c31b-b0c7-4986-b546-3f75f0fd9542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Guardar en formato Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ceee35c-5686-4d18-9af1-6ef3d8c6308c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Uni√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f68037a5-9c39-4290-ad31-d1ad0915a73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Paso 1: Unir los dos DataFrames en una tabla \"Golden\" ---\n",
    "# Usamos un 'inner join' para quedarnos solo con los ratings que tienen una pel√≠cula asociada.\n",
    "\n",
    "# Es una buena pr√°ctica renombrar las columnas antes del join para evitar ambig√ºedades,\n",
    "# aunque en este caso 'movieId' es la √∫nica en com√∫n y es la clave del join.\n",
    "# El join se realizar√° autom√°ticamente en esta columna.\n",
    "\n",
    "golden_df = ratings_clean_df.join(\n",
    "    movies_clean_df,\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Vista previa de la tabla 'Golden' unida y desnormalizada:\")\n",
    "golden_df.printSchema()\n",
    "golden_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8bc6d06-d787-4250-bacc-a50edad40db3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Guardar versi√≥n final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c5290f8-c6c5-46a5-8994-fd2602fcf626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Paso 2: Guardar la Tabla Golden en formato Delta Lake (Corregido) ---\n",
    "\n",
    "delta_path = \"/Volumes/workspace/movie/movielens/delta_tables/movielens_analyzed_final\"\n",
    "# Particionamos por 'year' porque es una columna de baja cardinalidad\n",
    "# y muy com√∫n para filtrar en an√°lisis de series temporales.\n",
    "(golden_df.write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy(\"year\")\n",
    " .option(\"overwriteSchema\", \"true\")\n",
    " .save(delta_path))\n",
    "\n",
    "print(f\"‚úÖ Tabla 'Golden' guardada exitosamente en Delta Lake en: {delta_path}\")\n",
    "\n",
    "# --- Validaci√≥n Final ---\n",
    "print(\"\\nüîç Validaci√≥n: Leyendo la tabla final desde Delta Lake:\")\n",
    "final_df = spark.read.format(\"delta\").load(delta_path)\n",
    "final_df.show(5)\n",
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38dbc977-736a-40ce-ba32-5a087e6a102c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc52e794-6c4b-41c8-813e-845f6c5ed061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Popularidad por g√©nero\n",
    "Dice qu√© generos reciben mas ratings. Los g√©neros mas populares a su vez reciben muchas cr√≠ticas de un mismo tipo acumulandose y sesgando el promedio final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b62cd8c-3c57-4cf6-bf1e-64cafca8131c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvdW50LCBhdmcsIGRlc2MKCiMgQ2FsY3VsYXIgZWwgbsO6bWVybyBkZSByYXRpbmdzIHBvciBnw6luZXJvCmdlbnJlX3BvcHVsYXJpdHlfZGYgPSBnb2xkZW5fZGYuZ3JvdXBCeSgiZ2VucmUiKS5hZ2coY291bnQoInJhdGluZyIpLmFsaWFzKCJudW1fcmF0aW5ncyIpKS5vcmRlckJ5KGRlc2MoIm51bV9yYXRpbmdzIikpCgpwcmludCgiUG9wdWxhcmlkYWQgZGUgbG9zIGfDqW5lcm9zIHBvciBuw7ptZXJvIGRlIHJhdGluZ3M6IikKZ2VucmVfcG9wdWxhcml0eV9kZi5zaG93KCkKCiMgLS0tIFZpc3VhbGl6YWNpw7NuIC0tLQpkaXNwbGF5KGdlbnJlX3BvcHVsYXJpdHlfZGYp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewe95159a\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewe95159a\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewe95159a\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewe95159a) SELECT `genre`,SUM(`num_ratings`) `column_76c86a5a310` FROM q GROUP BY `genre`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewe95159a\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "genre",
             "id": "column_76c86a5a309"
            },
            "y": [
             {
              "column": "num_ratings",
              "id": "column_76c86a5a310",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_76c86a5a310": {
             "name": "num_ratings",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": false,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "e00a6c34-0f53-4ef3-9f7a-7e4ea07abdb4",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "genre",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "genre",
           "type": "column"
          },
          {
           "alias": "column_76c86a5a310",
           "args": [
            {
             "column": "num_ratings",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, avg, desc\n",
    "\n",
    "# Calcular el n√∫mero de ratings por g√©nero\n",
    "genre_popularity_df = golden_df.groupBy(\"genre\").agg(count(\"rating\").alias(\"num_ratings\")).orderBy(desc(\"num_ratings\"))\n",
    "\n",
    "print(\"Popularidad de los g√©neros por n√∫mero de ratings:\")\n",
    "genre_popularity_df.show()\n",
    "\n",
    "# --- Visualizaci√≥n ---\n",
    "display(genre_popularity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf8d32ab-8df7-4c66-89d4-55592860f157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Qu√© porcentaje representan los ratings de Film-Noir respecto a los ratings del g√©nero m√°s popular (Drama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fbe9bbf-2108-4ec8-89e6-c0def8d80222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cantidad de ratings de Film-Noir\n",
    "film_noir_count = golden_df.filter(col(\"genre\") == \"Film-Noir\").count()\n",
    "\n",
    "# Cantidad de ratings de Drama (el m√°s popular)\n",
    "drama_count = golden_df.filter(col(\"genre\") == \"Drama\").count()\n",
    "\n",
    "# Porcentaje\n",
    "percentage = (film_noir_count / drama_count) * 100\n",
    "\n",
    "print(f\"Film-Noir representa el {percentage:.2f}% de los ratings de Drama.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7bd95af-2b33-41e1-a9ba-921656bfeece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Promedio de rating por g√©nero (sin corregir sesgo a√∫n)\n",
    "Muestra la media aritm√©tica cl√°sica. Generos con pocos ratings pueden tener promedios inflados. Generos muy populares con miles de pel√≠culas quedan penalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb62ebf-63b0-4cfa-bb07-408a93d5ef76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"Z2VucmVfYXZnX3JhdGluZ19kZiA9ICgKICAgIGdvbGRlbl9kZgogICAgLmdyb3VwQnkoImdlbnJlIikKICAgIC5hZ2coYXZnKCJyYXRpbmciKS5hbGlhcygiYXZnX3JhdGluZyIpKQogICAgLm9yZGVyQnkoZGVzYygiYXZnX3JhdGluZyIpKQopCgpwcmludCgiUHJvbWVkaW8gc2ltcGxlIGRlIHJhdGluZyBwb3IgZ8OpbmVybzoiKQpnZW5yZV9hdmdfcmF0aW5nX2RmLnNob3coKQoKZGlzcGxheShnZW5yZV9hdmdfcmF0aW5nX2RmKQo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView0bf817c\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView0bf817c\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView0bf817c\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView0bf817c) SELECT `genre`,SUM(`avg_rating`) `column_842ec5a0138` FROM q GROUP BY `genre`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView0bf817c\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "genre",
             "id": "column_842ec5a0137"
            },
            "y": [
             {
              "column": "avg_rating",
              "id": "column_842ec5a0138",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_842ec5a0138": {
             "name": "avg_rating",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": false,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "d040a1dc-6a71-41ed-816f-41adcf6682a4",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.8125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "genre",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "genre",
           "type": "column"
          },
          {
           "alias": "column_842ec5a0138",
           "args": [
            {
             "column": "avg_rating",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "genre_avg_rating_df = (\n",
    "    golden_df\n",
    "    .groupBy(\"genre\")\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\"))\n",
    "    .orderBy(desc(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "print(\"Promedio simple de rating por g√©nero:\")\n",
    "genre_avg_rating_df.show()\n",
    "\n",
    "display(genre_avg_rating_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab4413b7-1f1e-4274-806b-eb7d1d1a8c0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bayesian Adjust Average\n",
    "No favorece a g√©neros con pocos ratings ni castiga a generos con muchos ratings. Es la forma mas justa porque es un promedio ponderado entre:\n",
    "- Promedio del g√©nero (R)\n",
    "- Promedio global (C)\n",
    "- Ajustado por cuantos ratings tiene (v)\n",
    "- Ajustado por umbral de m√≠nimos ratings confiables (m = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32cea8c1-e10f-4d36-88fc-43797aefa800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBMb3MgZ8OpbmVyb3MgY29uIG11Y2hhcyBwZWzDrWN1bGFzIHN1ZWxlbiB0ZW5lciBtw6FzIHJhdGluZ3MgeSBwb3IgZW5kZSBlbCBwcm9tZWRpbyBwdWVkZSDigJxlbXB1amFyc2XigJ0gaGFjaWEgdmFsb3JlcyBtw6FzIGJham9zIG8gbcOhcyBhbHRvcy4KIyBMYSBmb3JtYSBlc3RhZMOtc3RpY2FtZW50ZSBjb3JyZWN0YSBkZSBvYnRlbmVyIHVuYSBwdW50dWFjacOzbiBwcm9tZWRpbyBubyBzZXNnYWRhIGVzIGFwbGljYXIgQmF5ZXNpYW4gQXZlcmFnZSBvIFJlZ3VsYXJpemVkIE1lYW4uCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCBjb2wsIGF2ZywgY291bnQsIGxpdAoKIyAxKSBwcm9tZWRpbyBnbG9iYWwKZ2xvYmFsX2F2ZyA9IGdvbGRlbl9kZi5zZWxlY3QoYXZnKCJyYXRpbmciKSkuZmlyc3QoKVswXQoKIyAyKSBuw7ptZXJvIHkgcHJvbWVkaW8gcG9yIGfDqW5lcm8KZ2VucmVfc3RhdHNfZGYgPSAoCiAgICBnb2xkZW5fZGYKICAgIC5ncm91cEJ5KCJnZW5yZSIpCiAgICAuYWdnKAogICAgICAgIGNvdW50KCJyYXRpbmciKS5hbGlhcygidiIpLAogICAgICAgIGF2ZygicmF0aW5nIikuYWxpYXMoIlIiKQogICAgKQopCgojIDMpIHBhcsOhbWV0cm8gbQptID0gMTAwMAoKIyA0KSBjYWxjdWxhbW9zIGVsIHByb21lZGlvIGFqdXN0YWRvCmdlbnJlX2FkanVzdGVkX2RmID0gKAogICAgZ2VucmVfc3RhdHNfZGYKICAgIC53aXRoQ29sdW1uKCJDIiwgbGl0KGdsb2JhbF9hdmcpKQogICAgLndpdGhDb2x1bW4oCiAgICAgICAgImFkanVzdGVkX3JhdGluZyIsCiAgICAgICAgKGNvbCgidiIpIC8gKGNvbCgidiIpICsgbSkpICogY29sKCJSIikgKwogICAgICAgIChsaXQobSkgLyAoY29sKCJ2IikgKyBtKSkgKiBjb2woIkMiKQogICAgKQogICAgLm9yZGVyQnkoY29sKCJhZGp1c3RlZF9yYXRpbmciKS5kZXNjKCkpCikKCnByaW50KCJSYXRpbmcgcHJvbWVkaW8gcG9yIGfDqW5lcm8gYWp1c3RhZG8gKHNpbiBzZXNnbyBwb3IgcG9wdWxhcmlkYWQpOiIpCmdlbnJlX2FkanVzdGVkX2RmLnNob3coKQoKZGlzcGxheShnZW5yZV9hZGp1c3RlZF9kZikK\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView0da35a8\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView0da35a8\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView0da35a8\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView0da35a8) SELECT `genre`,SUM(`adjusted_rating`) `column_842ec5a0151` FROM q GROUP BY `genre`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView0da35a8\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "genre",
             "id": "column_842ec5a0159"
            },
            "y": [
             {
              "column": "adjusted_rating",
              "id": "column_842ec5a0164",
              "transform": "AVG"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": ""
           },
           "seriesOptions": {
            "column_842ec5a0151": {
             "type": "column",
             "yAxis": 0
            },
            "column_842ec5a0164": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": false,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "830819cc-62d2-4387-bd89-65ee75f1e8b4",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.84375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "genre",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "genre",
           "type": "column"
          },
          {
           "alias": "column_842ec5a0164",
           "args": [
            {
             "column": "adjusted_rating",
             "type": "column"
            }
           ],
           "function": "AVG",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Los g√©neros con muchas pel√≠culas suelen tener m√°s ratings y por ende el promedio puede ‚Äúempujarse‚Äù hacia valores m√°s bajos o m√°s altos.\n",
    "# La forma estad√≠sticamente correcta de obtener una puntuaci√≥n promedio no sesgada es aplicar Bayesian Average o Regularized Mean.\n",
    "from pyspark.sql.functions import col, avg, count, lit\n",
    "\n",
    "# 1) promedio global\n",
    "global_avg = golden_df.select(avg(\"rating\")).first()[0]\n",
    "\n",
    "# 2) n√∫mero y promedio por g√©nero\n",
    "genre_stats_df = (\n",
    "    golden_df\n",
    "    .groupBy(\"genre\")\n",
    "    .agg(\n",
    "        count(\"rating\").alias(\"v\"),\n",
    "        avg(\"rating\").alias(\"R\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3) par√°metro m\n",
    "m = 1000\n",
    "\n",
    "# 4) calculamos el promedio ajustado\n",
    "genre_adjusted_df = (\n",
    "    genre_stats_df\n",
    "    .withColumn(\"C\", lit(global_avg))\n",
    "    .withColumn(\n",
    "        \"adjusted_rating\",\n",
    "        (col(\"v\") / (col(\"v\") + m)) * col(\"R\") +\n",
    "        (lit(m) / (col(\"v\") + m)) * col(\"C\")\n",
    "    )\n",
    "    .orderBy(col(\"adjusted_rating\").desc())\n",
    ")\n",
    "\n",
    "print(\"Rating promedio por g√©nero ajustado (sin sesgo por popularidad):\")\n",
    "genre_adjusted_df.show()\n",
    "\n",
    "display(genre_adjusted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb83022-1b88-46bd-b9b0-aea1fe4c5440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ratings_long_df = golden_df.select(\"genre\", \"rating\")\n",
    "\n",
    "display(ratings_long_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be5f5d8-a267-413a-b568-85905e72ef6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBDYWxjdWxhciBlbCByYXRpbmcgcHJvbWVkaW8gcG9yIGHDsW8KYXZnX3JhdGluZ19ieV95ZWFyX2RmID0gZ29sZGVuX2RmLmZpbHRlcihjb2woInllYXIiKS5pc05vdE51bGwoKSkuZ3JvdXBCeSgieWVhciIpLmFnZyhhdmcoInJhdGluZyIpLmFsaWFzKCJhdmdfcmF0aW5nIikpLm9yZGVyQnkoInllYXIiKQoKcHJpbnQoIlJhdGluZyBwcm9tZWRpbyBkZSBsYXMgcGVsw61jdWxhcyBwb3IgYcOxbyBkZSBsYW56YW1pZW50bzoiKQphdmdfcmF0aW5nX2J5X3llYXJfZGYuc2hvdygyMCkKCiMgLS0tIFZpc3VhbGl6YWNpw7NuIC0tLQpkaXNwbGF5KGF2Z19yYXRpbmdfYnlfeWVhcl9kZik=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView26a1f18\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView26a1f18\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView26a1f18\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView26a1f18) SELECT `year`,`avg_rating` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView26a1f18\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "year",
             "id": "column_76c86a5a319"
            },
            "y": [
             {
              "column": "avg_rating",
              "id": "column_76c86a5a320"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_76c86a5a320": {
             "name": "avg_rating",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "a035832e-0c8d-4c28-9adf-084c60226de2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.875,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "year",
           "type": "column"
          },
          {
           "column": "avg_rating",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular el rating promedio por a√±o\n",
    "avg_rating_by_year_df = golden_df.filter(col(\"year\").isNotNull()).groupBy(\"year\").agg(avg(\"rating\").alias(\"avg_rating\")).orderBy(\"year\")\n",
    "\n",
    "print(\"Rating promedio de las pel√≠culas por a√±o de lanzamiento:\")\n",
    "avg_rating_by_year_df.show(20)\n",
    "\n",
    "# --- Visualizaci√≥n ---\n",
    "display(avg_rating_by_year_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "198b7b94-9ac9-4096-a1d1-b811846e75f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Concusiones\n",
    "\n",
    "A partir del an√°lisis del dataset de MovieLens, se pueden extraer las siguientes conclusiones simples:\n",
    "\n",
    "1.  **Dominancia de G√©neros:** Los g√©neros de **Drama** y **Comedia** son los que concentran la mayor cantidad de ratings, lo que sugiere una fuerte preferencia del p√∫blico por este tipo de contenido.\n",
    "\n",
    "2.  **Calidad vs. Antig√ºedad:** El an√°lisis del rating promedio por a√±o muestra que entre las decadas del 20 y el 80 las pel√≠culas tuvieron un rating algo sostenido a diferencia de epocas anteriores y posteriores."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "databricks-movielens",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
